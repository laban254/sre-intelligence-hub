{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Time Series Forecasting for Infrastructure Metrics\n",
                "\n",
                "## Objectives\n",
                "- Build a predictive model using an **LSTM (Long Short-Term Memory)** neural network in PyTorch.\n",
                "- Forecast future infrastructure load (e.g., CPU utilization) based on historical sequence data.\n",
                "- Learn how to flag anomalies when the actual metric deviates significantly from the LSTM's prediction.\n",
                "\n",
                "## Dataset\n",
                "- We will generate a synthetic time series of CPU usage showing daily patterns and injected anomalies.\n",
                "\n",
                "## Expected Outcome\n",
                "- A trained PyTorch LSTM model capable of predicting the next hour of CPU load.\n",
                "- A visualization comparing the predicted vs. actual load to spot anomalies.\n",
                "\n",
                "## Challenge\n",
                "- Can you modify the network to predict the *next 5 minutes* instead of just the next single minute?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "\n",
                "# Set device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "# Set seeds\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Generating Data\n",
                "We need a time series with a clear pattern that an LSTM can learn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_cpu_metrics(days=14, points_per_hour=60):\n",
                "    total_points = days * 24 * points_per_hour\n",
                "    t = np.linspace(0, days * 2 * np.pi, total_points)\n",
                "    \n",
                "    # Base daily sine wave\n",
                "    base_load = 40 + 20 * np.sin(t)\n",
                "    \n",
                "    # Add noise\n",
                "    noise = np.random.normal(0, 2, total_points)\n",
                "    \n",
                "    cpu_usage = base_load + noise\n",
                "    \n",
                "    # Inject an anomaly near the end\n",
                "    cpu_usage[-200:-180] += 30\n",
                "    \n",
                "    return np.clip(cpu_usage, 0, 100).reshape(-1, 1)\n",
                "\n",
                "data = generate_cpu_metrics()\n",
                "\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.plot(data[-1000:], label=\"CPU Usage\") # Plot last ~16 hours\n",
                "plt.title(\"CPU Usage with Anomaly at the end\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Preprocessing for PyTorch\n",
                "Neural networks train best when data is scaled between -1 and 1 or 0 and 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
                "scaled_data = scaler.fit_transform(data)\n",
                "\n",
                "# Function to create sequences\n",
                "def create_sequences(data, seq_length):\n",
                "    xs = []\n",
                "    ys = []\n",
                "    for i in range(len(data)-seq_length-1):\n",
                "        x = data[i:(i+seq_length)]\n",
                "        y = data[i+seq_length]\n",
                "        xs.append(x)\n",
                "        ys.append(y)\n",
                "    return np.array(xs), np.array(ys)\n",
                "\n",
                "SEQ_LENGTH = 60 # Look back 60 minutes to predict the next 1 minute\n",
                "\n",
                "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
                "\n",
                "# Split into train/test (chronologically! Don't shuffle time series data initially)\n",
                "train_size = int(len(X) * 0.8)\n",
                "X_train, y_train = X[:train_size], y[:train_size]\n",
                "X_test, y_test = X[train_size:], y[train_size:]\n",
                "\n",
                "# Convert to PyTorch tensors\n",
                "X_train = torch.from_numpy(X_train).float().to(device)\n",
                "y_train = torch.from_numpy(y_train).float().to(device)\n",
                "X_test = torch.from_numpy(X_test).float().to(device)\n",
                "y_test = torch.from_numpy(y_test).float().to(device)\n",
                "\n",
                "# Create DataLoaders\n",
                "batch_size = 64\n",
                "train_data = TensorDataset(X_train, y_train)\n",
                "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Defining the LSTM Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CPUForecaster(nn.Module):\n",
                "    def __init__(self, input_size=1, hidden_size=32, num_layers=1, output_size=1):\n",
                "        super(CPUForecaster, self).__init__()\n",
                "        self.hidden_size = hidden_size\n",
                "        self.num_layers = num_layers\n",
                "        \n",
                "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
                "        self.fc = nn.Linear(hidden_size, output_size)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # Initialize hidden state with zeros\n",
                "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
                "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
                "        \n",
                "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
                "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
                "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
                "        \n",
                "        # Index hidden state of last time step\n",
                "        out = self.fc(out[:, -1, :]) \n",
                "        return out\n",
                "\n",
                "model = CPUForecaster().to(device)\n",
                "criterion = nn.MSELoss() # Mean Squared Error is standard for regression/time-series\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 10\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for batch_X, batch_y in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(batch_X)\n",
                "        loss = criterion(outputs, batch_y)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "        \n",
                "    if (epoch+1) % 2 == 0:\n",
                "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(train_loader):.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Evaluation and Anomaly Detection\n",
                "When a model accurately predicts the time series, a sudden large gap between `Actual` and `Predicted` indicates an anomaly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    test_predictions = model(X_test)\n",
                "\n",
                "# Inverse transform to get back to original CPU percentages\n",
                "predictions_inv = scaler.inverse_transform(test_predictions.cpu().numpy())\n",
                "y_test_inv = scaler.inverse_transform(y_test.cpu().numpy())\n",
                "\n",
                "# Calculate Error\n",
                "errors = np.abs(predictions_inv - y_test_inv)\n",
                "threshold = np.mean(errors) + 3 * np.std(errors) # 3 standard deviations for anomaly threshold\n",
                "\n",
                "# Plot the last 400 points of the test set\n",
                "points_to_plot = 400\n",
                "plt.figure(figsize=(15, 6))\n",
                "\n",
                "plt.plot(y_test_inv[-points_to_plot:], label='Actual Load', alpha=0.5, color='blue')\n",
                "plt.plot(predictions_inv[-points_to_plot:], label='Predicted Load', linestyle='dashed', color='green')\n",
                "\n",
                "# Highlight points where error > threshold\n",
                "recent_errors = errors[-points_to_plot:]\n",
                "anomalies = np.where(recent_errors > threshold)[0]\n",
                "plt.scatter(anomalies, y_test_inv[-points_to_plot:][anomalies], color='red', label='Detected Anomaly', zorder=5)\n",
                "\n",
                "plt.title(\"LSTM Forecasting & Anomaly Detection\")\n",
                "plt.ylabel(\"CPU %\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}