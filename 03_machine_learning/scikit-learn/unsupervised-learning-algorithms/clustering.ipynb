{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clustering for Incident and Workload Analysis\n",
                "\n",
                "## Context\n",
                "In SRE and DevOps, we often deal with massive amounts of unlabeled data, such as API request logs, server telemetry, or user behavior metrics. Clustering is an **Unsupervised Learning** technique that helps us discover inherent groupings in this data without needing pre-labeled examples.\n",
                "\n",
                "For instance, we can use clustering to:\n",
                "- Group similar API endpoints based on their performance profiles (Latency vs. Error Rate).\n",
                "- Discover distinct workload patterns across a fleet of microservices.\n",
                "- Detect anomalies (data points that do not fit into any normal cluster).\n",
                "\n",
                "## Objectives\n",
                "- Generate synthetic API telemetry data representing different endpoint behaviors.\n",
                "- Use **K-Means Clustering** to group healthy, slow, and failing endpoints.\n",
                "- Use **DBSCAN** to identify isolated anomalies (outliers) in the telemetry data.\n",
                "- Implement **Hierarchical Clustering** to visualize endpoint relationships in a dendrogram."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.cluster import KMeans, DBSCAN\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from scipy.cluster.hierarchy import dendrogram, linkage\n",
                "from sklearn.datasets import make_blobs\n",
                "\n",
                "plt.style.use('ggplot')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Generating API Telemetry Data\n",
                "We will synthesize a dataset of 300 APIs with two primary metrics:\n",
                "- **Latency (ms)**\n",
                "- **Error Rate (%)**\n",
                "\n",
                "We expect the APIs to naturally form 3 clusters:\n",
                "1. **Healthy:** Low latency (e.g., ~50ms), Low errors (e.g., ~0.1%)\n",
                "2. **Slow / Performance Issues:** High latency (e.g., ~500ms), Low errors\n",
                "3. **Failing / Reliability Issues:** Low latency, High errors (e.g., ~5%)\n",
                "\n",
                "We will also add some \"noise\" (anomalous data points)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "\n",
                "# Create 3 distinct clusters\n",
                "X_clusters, _ = make_blobs(\n",
                "    n_samples=300, \n",
                "    centers=[[50, 0.1], [500, 0.2], [40, 5.0]], # Centers for Healthy, Slow, Failing\n",
                "    cluster_std=[10, 0.05], # Variance for Latency and Error Rate\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Add some random anomalies (noise)\n",
                "noise = np.random.uniform(low=[100, 1.0], high=[800, 8.0], size=(20, 2))\n",
                "X = np.vstack([X_clusters, noise])\n",
                "\n",
                "# Put into DataFrame for easier handling\n",
                "df = pd.DataFrame(X, columns=['Latency_ms', 'Error_Rate_pct'])\n",
                "\n",
                "# It is highly recommended to scale the features before clustering,\n",
                "# otherwise Latency (which is 10s-100s) will completely dominate Error Rate (which is 0-5).\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(df)\n",
                "\n",
                "# Visualize the unclustered data\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.scatterplot(x='Latency_ms', y='Error_Rate_pct', data=df, s=50, alpha=0.7)\n",
                "plt.title(\"Raw API Telemetry (Unlabeled)\")\n",
                "plt.xlabel(\"Average Latency (ms)\")\n",
                "plt.ylabel(\"Error Rate (%)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. K-Means Clustering\n",
                "K-Means partitions the dataset into exactly `K` clusters, aiming to minimize the variance within each cluster. Each point is assigned to the nearest centroid.\n",
                "\n",
                "Here, we'll tell K-Means to look for $K=3$ clusters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply K-Means\n",
                "kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')\n",
                "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
                "df['KMeans_Cluster'] = kmeans_labels\n",
                "\n",
                "# To plot centroids on original scale, inverse transform them\n",
                "centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.scatterplot(x='Latency_ms', y='Error_Rate_pct', hue='KMeans_Cluster', data=df, palette='Set1', s=60, alpha=0.8)\n",
                "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, marker='X', label='Centroids')\n",
                "\n",
                "plt.title(\"K-Means Clustering of APIs (K=3)\")\n",
                "plt.xlabel(\"Average Latency (ms)\")\n",
                "plt.ylabel(\"Error Rate (%)\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Insight: K-Means successfully separated the Healthy, Slow, and Failing groups. \n",
                "# Notice that it forcefully assigns the 'noise' anomalies into one of the 3 clusters."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Choosing the right 'K' (The Elbow Method)\n",
                "If we didn't know in advance that there are 3 intrinsic groups, how would we pick `K`? \n",
                "We can calculate the **Inertia** (sum of squared distances from points to their centroids) for different values of `K`. The \"elbow\" point of the curve is typically optimal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inertia = []\n",
                "K_range = range(1, 8)\n",
                "for k in K_range:\n",
                "    km = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
                "    km.fit(X_scaled)\n",
                "    inertia.append(km.inertia_)\n",
                "    \n",
                "plt.figure(figsize=(7, 4))\n",
                "plt.plot(K_range, inertia, marker='o', linestyle='--')\n",
                "plt.title('Elbow Method For Optimal K')\n",
                "plt.xlabel('Number of Clusters (K)')\n",
                "plt.ylabel('Inertia')\n",
                "plt.axvline(x=3, color='blue', linestyle=':')\n",
                "plt.show()\n",
                "# The bend at K=3 strongly suggests 3 is the natural number of groupings here."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
                "Unlike K-Means, DBSCAN does not require specifying the number of clusters in advance. It groups points that are densely packed together, and marks points in low-density regions as **outliers (noise)**.\n",
                "\n",
                "This is arguably more powerful for SRE use cases, as incident detection is often a problem of finding anomalies (noise) versus regular workload trends (dense clusters).\n",
                "\n",
                "**Key Parameters:**\n",
                "- **`eps`**: The maximum distance between two points to be considered neighbors.\n",
                "- **`min_samples`**: The minimum number of points required to form a dense region (a cluster)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply DBSCAN\n",
                "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
                "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
                "df['DBSCAN_Cluster'] = dbscan_labels\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.scatterplot(x='Latency_ms', y='Error_Rate_pct', hue='DBSCAN_Cluster', data=df, palette='Dark2', s=60, alpha=0.9)\n",
                "\n",
                "plt.title(\"DBSCAN Clustering (Cluster -1 = Anomalies)\")\n",
                "plt.xlabel(\"Average Latency (ms)\")\n",
                "plt.ylabel(\"Error Rate (%)\")\n",
                "plt.legend(title='DBSCAN Label')\n",
                "plt.show()\n",
                "\n",
                "# Insight: DBSCAN found 3 main clusters (0, 1, 2) and correctly identified the scattered \n",
                "# noise points as anomalies by assigning them a label of '-1'.\n",
                "# These '-1' APIs are candidates for immediate alerting or deep-dive investigations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Hierarchical Clustering\n",
                "Hierarchical clustering builds a \"tree\" of clusters (a dendrogram), showing how individual data points merge together into the final clusters. This is helpful for understanding the hierarchical taxonomy of your services. \n",
                "*(We will use a small subset of the data so the dendrogram is readable)*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Take a small random sample (30 points) for visualization\n",
                "df_sample = df.sample(n=30, random_state=42)\n",
                "X_subset_scaled = scaler.transform(df_sample[['Latency_ms', 'Error_Rate_pct']])\n",
                "\n",
                "# Calculate the linkage matrix using Ward's method (minimizes variance when merging)\n",
                "Z = linkage(X_subset_scaled, method='ward')\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "dendrogram(\n",
                "    Z, \n",
                "    labels=df_sample.index.to_numpy(), \n",
                "    leaf_rotation=90.,\n",
                "    color_threshold=3.5 # Threshold to color the distinct branches\n",
                ")\n",
                "plt.title(\"Hierarchical Clustering Dendrogram (Subset)\")\n",
                "plt.xlabel(\"API Data Point Index\")\n",
                "plt.ylabel(\"Distance (Ward)\")\n",
                "plt.show()\n",
                "\n",
                "# Insight: You can see at a high level the dataset splits into 3 primary tree branches,\n",
                "# mirroring our 3 main groups (Healthy, Slow, Failing)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}