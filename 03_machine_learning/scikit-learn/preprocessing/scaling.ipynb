{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Feature Scaling for Infrastructure Metrics\n",
                "\n",
                "## Context\n",
                "In SRE and observability, metrics exist on vastly different scales. For instance, CPU utilization is typically a percentage `[0-100]`, while Network Bytes In might be in the millions or billions `[10^6 - 10^9]`. \n",
                "\n",
                "When using distance-based Machine Learning models (like K-Means Clustering, PCA, or Support Vector Machines), features with larger ranges will disproportionately dominate the algorithm. To prevent an alert firing *only* because of network traffic and ignoring CPU spikes, we must **scale** our features.\n",
                "\n",
                "## Objectives\n",
                "- Load synthetic server telemetry with variables of drastically different scales.\n",
                "- Implement and understand **StandardScaler** (Z-score normalization).\n",
                "- Implement and understand **MinMaxScaler** (Normalization to a specific range).\n",
                "- Visualize the effect of scaling on the data distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "plt.style.use('ggplot')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Generating Disparate Telemetry Data\n",
                "Let's create a dataset where Network Traffic dwarfs CPU usage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n_samples = 500\n",
                "\n",
                "# Feature 1: CPU Usage ranges mostly from 10% to 90%\n",
                "cpu_usage = np.random.normal(loc=50, scale=15, size=n_samples)\n",
                "\n",
                "# Feature 2: Network Traffic (Bytes/sec) ranges in the millions\n",
                "network_traffic = np.random.normal(loc=5_000_000, scale=1_000_000, size=n_samples)\n",
                "\n",
                "df = pd.DataFrame({\n",
                "    'CPU_Usage_pct': cpu_usage,\n",
                "    'Network_Bytes_Sec': network_traffic\n",
                "})\n",
                "\n",
                "# Plotting the unscaled data\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.scatterplot(x='CPU_Usage_pct', y='Network_Bytes_Sec', data=df, alpha=0.7)\n",
                "plt.title(\"Unscaled Server Metrics\")\n",
                "plt.xlabel(\"CPU Usage (%)\")\n",
                "plt.ylabel(\"Network Traffic (Bytes/sec)\")\n",
                "plt.show()\n",
                "\n",
                "print(\"Data Describe (Notice the massive difference in scale):\")\n",
                "print(df.describe().round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Standardization (`StandardScaler`)\n",
                "\n",
                "Standardization (or Z-score normalization) transforms the data so that it has a **mean of 0** and a **standard deviation of 1**.\n",
                "This is the go-to default scaling method for many ML algorithms (like Logistic Regression, SVMs, and PCA).\n",
                "\n",
                "Formula: $z = \\frac{(x - \\mu)}{\\sigma}$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split into train and test sets to prevent data leakage\n",
                "X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)\n",
                "\n",
                "# Initialize StandardScaler\n",
                "std_scaler = StandardScaler()\n",
                "\n",
                "# Fit on training data AND transform it\n",
                "X_train_std = pd.DataFrame(std_scaler.fit_transform(X_train), columns=X_train.columns)\n",
                "\n",
                "# Transform test data based on the mean/std learned from training data\n",
                "X_test_std = pd.DataFrame(std_scaler.transform(X_test), columns=X_test.columns)\n",
                "\n",
                "print(\"Mean after standardization (should be ~0):\")\n",
                "print(X_train_std.mean().round(2))\n",
                "print(\"\\nStandard Deviation after standardization (should be ~1):\")\n",
                "print(X_train_std.std().round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Normalization (`MinMaxScaler`)\n",
                "\n",
                "Min-Max scaling shrinks the data into a fixed range, usually **0 to 1**. \n",
                "This is often used in Neural Networks (like CNNs or ANNs) or when you need bounded values (e.g., image pixels)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize MinMaxScaler\n",
                "minmax_scaler = MinMaxScaler()\n",
                "\n",
                "X_train_minmax = pd.DataFrame(minmax_scaler.fit_transform(X_train), columns=X_train.columns)\n",
                "X_test_minmax = pd.DataFrame(minmax_scaler.transform(X_test), columns=X_test.columns)\n",
                "\n",
                "print(\"Min values after scaling (should be 0):\")\n",
                "print(X_train_minmax.min().round(2))\n",
                "print(\"\\nMax values after scaling (should be 1):\")\n",
                "print(X_train_minmax.max().round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Visualizing the Difference\n",
                "Let's look at how the data distribution shape remains identical, but the axes (scales) change drastically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "# 1. Original\n",
                "sns.scatterplot(x='CPU_Usage_pct', y='Network_Bytes_Sec', data=X_train, ax=axes[0], alpha=0.7)\n",
                "axes[0].set_title(\"Original Data\")\n",
                "\n",
                "# 2. Standardized\n",
                "sns.scatterplot(x='CPU_Usage_pct', y='Network_Bytes_Sec', data=X_train_std, ax=axes[1], alpha=0.7, color='blue')\n",
                "axes[1].set_title(\"StandardScaler (Mean=0, Std=1)\")\n",
                "\n",
                "# 3. Normalized\n",
                "sns.scatterplot(x='CPU_Usage_pct', y='Network_Bytes_Sec', data=X_train_minmax, ax=axes[2], alpha=0.7, color='green')\n",
                "axes[2].set_title(\"MinMaxScaler (0 to 1)\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Notice that the geometric shape of the points is exactly the same across all three plots.\n",
                "# However, looking at the X and Y axes, we see the scales have been leveled out, ensuring\n",
                "# Network Traffic doesn't accidentally completely overshadow CPU Usage."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}