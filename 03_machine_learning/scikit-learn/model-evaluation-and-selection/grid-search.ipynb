{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Selection & Tuning: Grid Search\n",
                "\n",
                "## Context\n",
                "Machine Learning algorithms have settings called **Hyperparameters** that you must set before training. For a Decision Tree, it's `max_depth`. For a Support Vector Machine, it's `C` and the `kernel`.\n",
                "\n",
                "Choosing the perfect configuration manually is basically guessing. Instead, we use **Grid Search** to automatically train and evaluate the model using a grid of thousands of possible hyperparameter combinations to find the absolute best setup for predicting our infrastructure events.\n",
                "\n",
                "## Objectives\n",
                "- Generate a dataset predicting \"API Timeout Alerts\" based on concurrency and DB queries.\n",
                "- Use `GridSearchCV` to exhaustively test hyperparameters for a Random Forest classifier.\n",
                "- Safely pick the best model for continuous integration/deployment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Generating API Telemetry Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n_samples = 600\n",
                "\n",
                "X = pd.DataFrame({\n",
                "    'Concurrent_Users': np.random.normal(500, 200, n_samples),\n",
                "    'DB_Queries_Per_Sec': np.random.normal(2000, 500, n_samples)\n",
                "})\n",
                "\n",
                "# Timeout alert triggers heavily when Users > 700 AND DB queries > 2200\n",
                "y = ((X['Concurrent_Users'] > 700) & (X['DB_Queries_Per_Sec'] > 2200)).astype(int)\n",
                "noise = np.random.choice(n_samples, size=50, replace=False)\n",
                "y[noise] = 1 - y[noise]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. The Baseline Model (Guessing Hyperparameters)\n",
                "Let's see how our model performs when we just use the default settings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline_rf = RandomForestClassifier(random_state=42)\n",
                "baseline_rf.fit(X_train, y_train)\n",
                "\n",
                "baseline_pred = baseline_rf.predict(X_test)\n",
                "print(\"Baseline Accuracy: {:.2f}%\".format(accuracy_score(y_test, baseline_pred) * 100))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Defining the Hyperparameter Grid\n",
                "We will tell Scikit-Learn to test every single combination of the following rules:\n",
                "- `n_estimators` (Number of trees): 50, 100, or 200.\n",
                "- `max_depth` (Deepest a tree can grow): None (infinite), 5, or 10.\n",
                "- `min_samples_split`: 2, 5, or 10.\n",
                "\n",
                "This means it will train $3 \\times 3 \\times 3 = 27$ different models. Since we also use 5-Fold Cross Validation for each, it will train a total of **135 models**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [None, 5, 10],\n",
                "    'min_samples_split': [2, 5, 10]\n",
                "}\n",
                "\n",
                "print(\"Grid search will evaluate combination of parameters:\", param_grid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Executing `GridSearchCV`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize GridSearchCV\n",
                "# n_jobs=-1 tells Scikit-Learn to use ALL your CPU cores to train models in parallel\n",
                "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
                "                           param_grid=param_grid, \n",
                "                           cv=5, \n",
                "                           n_jobs=-1, \n",
                "                           verbose=1)  # Verbose=1 prints training progress\n",
                "\n",
                "# Fit it (This loops through all 135 models)\n",
                "grid_search.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Reviewing Results\n",
                "Let's see what the \"winning\" combination was and evaluate it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Best Hyperparameters Found: \", grid_search.best_params_)\n",
                "print(\"Best CV Accuracy: {:.2f}%\\n\".format(grid_search.best_score_ * 100))\n",
                "\n",
                "# The grid_search object automatically retains the BEST model so you can use it immediately\n",
                "best_model = grid_search.best_estimator_\n",
                "optimized_pred = best_model.predict(X_test)\n",
                "\n",
                "print(\"Optimized Test Accuracy: {:.2f}%\".format(accuracy_score(y_test, optimized_pred) * 100))\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, optimized_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Summary\n",
                "In automated ML pipelines (like retraining a model weekly on fresh Logstash data), `GridSearchCV` lets the script continuously discover the best parameters without a human Data Scientist needing to manually tinker with variables."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}