{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Evaluation: Cross-Validation\n",
                "\n",
                "## Context\n",
                "In observability and ML, relying on a single train/test split can be dangerously misleading. A model predicting server outages might get \"lucky\" on one specific test set that happens to be easy, giving you false confidence before deploying it to production.\n",
                "\n",
                "**K-Fold Cross-Validation** solves this by splitting the data into `K` different chunks (folds). It trains the model `K` times, each time using a different chunk as the test set and the remaining as training data. This gives us a robust **average accuracy** and a **variance** (how much the performance fluctuates).\n",
                "\n",
                "## Objectives\n",
                "- Generate a synthetic SRE dataset predicting \"System Outage\".\n",
                "- Train a model on a simple Train/Test split.\n",
                "- Use `cross_val_score` to perform 5-Fold Cross-Validation.\n",
                "- Visualize the stability of the model across different folds."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Generate SRE Outage Data\n",
                "We will synthesize metrics (CPU, Memory, Disk Queue Length) to predict an `Outage_Flag`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n_samples = 400\n",
                "\n",
                "X = pd.DataFrame({\n",
                "    'CPU_Load': np.random.normal(50, 20, n_samples),\n",
                "    'Mem_Usage': np.random.normal(60, 15, n_samples),\n",
                "    'Disk_Queue': np.random.poisson(2, n_samples)\n",
                "})\n",
                "\n",
                "# Outage occurs if resource contention is high across the board\n",
                "y = ((X['CPU_Load'] > 80) & (X['Mem_Usage'] > 80) | (X['Disk_Queue'] >= 6)).astype(int)\n",
                "\n",
                "# Introduce noise to make it realistic\n",
                "noise = np.random.choice(n_samples, size=30, replace=False)\n",
                "y[noise] = 1 - y[noise]\n",
                "\n",
                "print(\"Outage Distribution:\\n\", y.value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. The Danger of a Single Split\n",
                "Let's see the accuracy with a single 80/20 train/test split."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "single_split_acc = accuracy_score(y_test, model.predict(X_test))\n",
                "print(\"Single Split Accuracy: {:.2f}%\".format(single_split_acc * 100))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. K-Fold Cross-Validation\n",
                "Now, let's use 5-Fold Cross Validation on the entire dataset. This will train and test the model 5 separate times on 5 completely different chunks of the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# cv=5 means 5-Fold Cross Validation\n",
                "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
                "\n",
                "print(\"Accuracy for each fold:\", np.round(cv_scores * 100, 2))\n",
                "print(\"\\nAverage Accuracy: {:.2f}%\".format(cv_scores.mean() * 100))\n",
                "print(\"Standard Deviation: {:.2f}% (How much the performance fluctuates)\".format(cv_scores.std() * 100))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Visualizing Model Stability\n",
                "A boxplot easily shows us if the ML model's accuracy is stable or highly dependent on how the data was split."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(6, 4))\n",
                "plt.boxplot(cv_scores * 100)\n",
                "plt.title(\"Cross-Validation Accuracy Spread\")\n",
                "plt.ylabel(\"Accuracy (%)\")\n",
                "plt.xticks([1], [\"Random Forest (5 Folds)\"])\n",
                "plt.axhline(single_split_acc * 100, color='red', linestyle='--', label='Original Single Split')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Interpretation: If the box is very tall (high standard deviation), the model is volatile \n",
                "# and might not be trustworthy in production alerting systems."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Stratified K-Fold (Important for SRE)\n",
                "In infrastructure, outages are rare. Usually, 95% of data is \"Healthy\" and 5% is \"Failure\". \n",
                "If you just randomly split data, one fold might accidentally contain 0 failures! \n",
                "\n",
                "**StratifiedKFold** guarantees that the ratio of Healthy vs Failure is preserved in every single fold."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "stratified_cv_scores = cross_val_score(model, X, y, cv=stratified_kfold, scoring='accuracy')\n",
                "\n",
                "print(\"Stratified Average Accuracy: {:.2f}%\".format(stratified_cv_scores.mean() * 100))\n",
                "\n",
                "# Always default to Stratified K-Fold when dealing with heavily imbalanced SRE logs!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}