{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Predicting Server Health State with Classification\n",
                "\n",
                "## Context\n",
                "As an SRE, you want to automatically categorize the health state of your infrastructure (e.g., *Healthy*, *Warning*, *Critical*) rather than relying purely on static, single-metric thresholds. By feeding historical telemetry data and their known incident states into a classification model, you can predict when a server is entering a problematic state before it fails entirely.\n",
                "\n",
                "## Objectives\n",
                "- Generate synthetic operational telemetry data mapped to server health states.\n",
                "- Train classification models: Logistic Regression, Random Forest Classifier, and Support Vector Classifier (SVC).\n",
                "- Evaluate model accuracy and analyze the classification report (Precision, Recall, F1-Score).\n",
                "- Understand feature importance to see which metrics drive state changes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "plt.style.use('ggplot')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Generating Synthetic Telemetry Data\n",
                "We will generate data representing 1,500 server snapshots. We'll label them as 0 (Healthy), 1 (Warning), or 2 (Critical) based on underlying rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n_samples = 1500\n",
                "\n",
                "# Telemetry features\n",
                "cpu_usage = np.random.uniform(10, 100, n_samples)\n",
                "memory_usage = np.random.uniform(20, 100, n_samples)\n",
                "disk_io = np.random.normal(500, 200, n_samples)\n",
                "network_latency = np.random.gamma(2, 10, n_samples)\n",
                "error_rate = np.random.exponential(1.5, n_samples)\n",
                "\n",
                "def determine_state(cpu, mem, error, latency):\n",
                "    # Combinations of high metrics lead to worse states\n",
                "    if error > 5 or (cpu > 90 and mem > 90):\n",
                "        return 2  # Critical\n",
                "    elif error > 2 or cpu > 75 or mem > 80 or latency > 40:\n",
                "        return 1  # Warning\n",
                "    else:\n",
                "        return 0  # Healthy\n",
                "\n",
                "# Apply logic to map features to a target state\n",
                "states = [determine_state(cpu_usage[i], memory_usage[i], error_rate[i], network_latency[i]) for i in range(n_samples)]\n",
                "\n",
                "df = pd.DataFrame({\n",
                "    'cpu_usage': cpu_usage,\n",
                "    'memory_usage': memory_usage,\n",
                "    'disk_io': disk_io,\n",
                "    'network_latency': network_latency,\n",
                "    'error_rate': error_rate,\n",
                "    'state': states\n",
                "})\n",
                "\n",
                "# Let's map integer states to string labels for clarity later\n",
                "state_map = {0: 'Healthy', 1: 'Warning', 2: 'Critical'}\n",
                "df['state_label'] = df['state'].map(state_map)\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Exploratory Data Analysis\n",
                "How does error rate distinguish between states?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8, 5))\n",
                "sns.boxplot(x='state_label', y='error_rate', data=df, order=['Healthy', 'Warning', 'Critical'], palette='viridis')\n",
                "plt.title('Error Rate by Server State')\n",
                "plt.ylabel('Error Rate (%)')\n",
                "plt.xlabel('')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Data Preparation (Scaling and Splitting)\n",
                "Machine learning models often require features to be on the same scale (e.g., Disk I/O is in the hundreds, Memory is 0-100). We use `StandardScaler` to normalize the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df[['cpu_usage', 'memory_usage', 'disk_io', 'network_latency', 'error_rate']]\n",
                "y = df['state']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# Scale the features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Training Classification Models\n",
                "\n",
                "#### **Model A: Logistic Regression**\n",
                "A foundational algorithm for classification. It works well if the boundary between states is relatively linear."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "log_reg = LogisticRegression(max_iter=1000)\n",
                "log_reg.fit(X_train_scaled, y_train)\n",
                "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
                "\n",
                "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_log_reg):.4f}\\n\")\n",
                "print(classification_report(y_test, y_pred_log_reg, target_names=['Healthy', 'Warning', 'Critical']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **Model B: Random Forest Classifier**\n",
                "An ensemble model that builds multiple decision trees. Highly effective and handles complex, non-linear relationships well (like our \"IF cpu > 90 AND mem > 90\" rule)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_clf.fit(X_train_scaled, y_train)\n",
                "y_pred_rf = rf_clf.predict(X_test_scaled)\n",
                "\n",
                "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\\n\")\n",
                "print(classification_report(y_test, y_pred_rf, target_names=['Healthy', 'Warning', 'Critical']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **Model C: Support Vector Classifier (SVC)**\n",
                "Finds the optimal hyperplane that separates the classes. Excellent for high-dimensional spaces."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "svc_clf = SVC(kernel='rbf', random_state=42)\n",
                "svc_clf.fit(X_train_scaled, y_train)\n",
                "y_pred_svc = svc_clf.predict(X_test_scaled)\n",
                "\n",
                "print(f\"SVC Accuracy: {accuracy_score(y_test, y_pred_svc):.4f}\\n\")\n",
                "print(classification_report(y_test, y_pred_svc, target_names=['Healthy', 'Warning', 'Critical']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Evaluation: Confusion Matrix\n",
                "Let's look at the Random Forest confusion matrix to see specifically *where* the model makes mistakes. Are we predicting \"Healthy\" when it's actually \"Critical\"? (This would be a dangerous false negative)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_test, y_pred_rf)\n",
                "\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['Healthy', 'Warning', 'Critical'],\n",
                "            yticklabels=['Healthy', 'Warning', 'Critical'])\n",
                "plt.xlabel('Predicted State')\n",
                "plt.ylabel('Actual State')\n",
                "plt.title('Confusion Matrix: Random Forest Classifier')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Feature Importance\n",
                "Random Forest models give us the ability to see which features contributed most to the predictions. This tells us which telemetry metrics are the strongest leading indicators of server failure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "importances = rf_clf.feature_importances_\n",
                "features = X.columns\n",
                "\n",
                "indices = np.argsort(importances)\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.barh(range(len(indices)), importances[indices], color='teal', align='center')\n",
                "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
                "plt.title('Feature Importances in Server State Prediction')\n",
                "plt.xlabel('Relative Importance')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}